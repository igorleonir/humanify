# Humanify
> Un-minify Javascript code using LLMs ("AI")

This tool uses large language modeles (like ChatGPT & llama2) and other tools to
un-minify Javascript code. Note that LLMs don't perform any structural changes â€“
they only provide hints to rename variables and functions. The heavy lifting is
done by Babel on AST level to ensure code stays 1-1 equivalent.

## Example

Given the following minified code:

```javascript
function a(e,t){var n=[];var r=e.length;var i=0;for(;i<r;i+=t){if(i+t<r){n.push(e.substring(i,i+t))}else{n.push(e.substring(i,r))}}return n}
```

The tool will output a human-readable version:

```javascript
function splitString(inputString, chunkSize) {
  var chunks = [];
  var stringLength = inputString.length;
  var startIndex = 0;
  for (; startIndex < stringLength; startIndex += chunkSize) {
    if (startIndex + chunkSize < stringLength) {
      chunks.push(inputString.substring(startIndex, startIndex + chunkSize));
    } else {
      chunks.push(inputString.substring(startIndex, stringLength));
    }
  }
  return chunks;
}
```

ðŸš¨ **NOTE:** ðŸš¨

Large files may take some time to process and use a lot of tokens if you use
ChatGPT. For a rough estimate, the tool takes about 2 tokens per character to
process a file:

```shell
echo "$((2 * $(wc -c < yourscript.min.js)))"
```

So for refrence: a minified `bootstrap.min.js` would take about $0.5 to
un-minify using ChatGPT.

Using `--local` flag is of course free, but may take more time, be less accurate
and not possible with your existing hardware.

## Getting started

First install the dependencies:

```shell
npm install
```

Next you'll need to decide wether to use ChatGPT or llama2. In a nutshell:

* ChatPGPT
  * Runs on someone else's computer that's specifically optimized for this kind
    of things
  * Costs money depending on the length of your code
  * Is more accurate
  * Is (probably) faster
* llama2
  * Runs locally
  * Is free
  * Is less accurate
  * Needs a local GPU with ~60gm RAM (M1 Mac works just fine)
  * Runs as fast as your GPU does

See instructions below for each option:

### ChatGPT

You'll need a ChatGPT API key. You can get one by signing up at
https://openai.com/.

There are several ways to provide the API key to the tool:
```shell
echo "OPENAI_TOKEN=your-token" > .env && npm start --  -o unminified.js minified-file.js
export OPENAI_TOKEN="your-token" && npm start --  -o unminified.js minified-file.js
OPENAI_TOKEN=your-token npm start --  -o unminified.js minified-file.js
npm start -- --key="your-token"  -o unminified.js minified-file.js
```

Use your preferred way to provide the API key. Use `npm start -- --help` to see
all available options.

### llama2

Prerequisited:
* You'll need to have a Python 3 environment with [conda installed][conda].
* You need a Huggingface account with access to [llama-2-7b-chat-hf
  model][llama2model]. Make sure to read the instructions on the model page
  about how to access the model.

[conda]: https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html
[llama2model]: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf

Run the following command to install the required Python packages and activate the environment:

```shell
conda env create -f environment.yml
conda activate base
```

You can now run the tool with:

```shell
npm start -- --local -o unminified.js minified-file.js
```

Note: this downloads ~13gb of model data to your computer on the first run.

## Features

The main features of the tool are:
* Uses ChatGPT functions/llama2 to get smart suggestions to rename variable and
  function names
* Uses custom and off-the-shelf Babel plugins to perform AST-level unmanging
* Uses Webcrack to unbundle Webpack bundles

## Contributing

If you'd like to contribute, please fork the repository and use a feature
branch. Pull requests are warmly welcome.

## Licensing

The code in this project is licensed under MIT license.
